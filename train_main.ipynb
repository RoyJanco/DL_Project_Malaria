{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "train_main.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "1. Imports"
   ],
   "metadata": {
    "id": "Yuk-Wy_aMMnm"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "from MALARIA2 import MALARIA\n",
    "import localizerVgg\n",
    "import utils\n",
    "from scipy.ndimage.filters import maximum_filter, median_filter\n",
    "from scipy.ndimage.morphology import generate_binary_structure, binary_erosion, grey_dilation\n",
    "import argparse\n",
    "import os.path"
   ],
   "metadata": {
    "id": "YYladmDqMOLO"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Hyper-parameters:"
   ],
   "metadata": {
    "id": "QOfdTJIWMQFz"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "NUM_CLASSES = 2\n",
    "LOSS_TYPE = 'l2'\n",
    "WEIGHT_MAP = False\n",
    "BETA = 0.9999\n",
    "EPOCHS = 1\n",
    "# CLASS_BALANCE = True"
   ],
   "metadata": {
    "id": "5hLM0U1KMSfI"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. Functions"
   ],
   "metadata": {
    "id": "CnY7X3tcdIxf"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Arguments\n",
    "def parse_args():\n",
    "    \"\"\"Parse script arguments \"\"\"\n",
    "    parser = argparse.ArgumentParser(description='Training models with Pytorch')\n",
    "    parser.add_argument('-f') # Dummy argument\n",
    "\n",
    "    parser.add_argument('--num_classes', '-c', default=NUM_CLASSES, type=int,\n",
    "                        help='Number of classes')\n",
    "    parser.add_argument('--loss_type', '-l', default=LOSS_TYPE, type=str,\n",
    "                        help='Loss function name: l2 or AW')\n",
    "    parser.add_argument('--weight_map', '-w', default=WEIGHT_MAP, type=bool,\n",
    "                        help='Weight map multiplied with loss: True or False')\n",
    "    # parser.add_argument('--class_balance', '-cb', default=CLASS_BALANCE, type=bool,\n",
    "    #                     help='Class balance: True or False')\n",
    "    parser.add_argument('--beta', '-b', default=BETA, type=float,\n",
    "                        help='Beta value for balancing the loss function. should be between 0 to 1')\n",
    "    parser.add_argument('--epochs', '-e', default=EPOCHS, type=int,\n",
    "                        help='Number of epochs to run')\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "class Loss(nn.Module):\n",
    "    \"\"\"e_ny is the effective number of samples in class y\"\"\"\n",
    "    def __init__(self, loss_type, weight_map_mode, e_ny):\n",
    "        super(Loss, self).__init__()\n",
    "        self.e_ny = e_ny\n",
    "        self.loss_type = loss_type\n",
    "        self.weight_map_mode = weight_map_mode\n",
    "\n",
    "        # AW loss parameters\n",
    "        self.omega = 14\n",
    "        self.theta = 0.5\n",
    "        self.epsilon = 1\n",
    "        self.alpha = 2.1\n",
    "\n",
    "        # Shrinkage loss parameters\n",
    "        self.a = 10\n",
    "        self.c = 0.2\n",
    "\n",
    "    def forward(self, y_pred, y, weight_map=1):\n",
    "        if self.loss_type == 'l2':\n",
    "            y_pred = torch.square(y_pred - y.float()) * weight_map\n",
    "            y_pred_sum = torch.sum(y_pred, dim=2)\n",
    "            # Sum over all elements and normalize\n",
    "            ret = torch.sum(y_pred_sum) / torch.numel(y_pred)\n",
    "            return ret\n",
    "\n",
    "        elif self.loss_type == 'AW':\n",
    "            delta_y = (y - y_pred).abs()\n",
    "            delta_y1 = delta_y[delta_y < self.theta]\n",
    "            delta_y2 = delta_y[delta_y >= self.theta]\n",
    "            y1 = y[delta_y < self.theta]\n",
    "            y2 = y[delta_y >= self.theta]\n",
    "            if self.weight_map_mode:\n",
    "                loss1 = self.omega * torch.log(1 + torch.pow(\n",
    "                    delta_y1 / self.epsilon, self.alpha - y1)) * weight_map[delta_y < self.theta]\n",
    "            else:\n",
    "                loss1 = self.omega * torch.log(1 + torch.pow(\n",
    "                    delta_y1 / self.epsilon, self.alpha - y1))\n",
    "            A = self.omega * (1 / (1 + torch.pow(self.theta / self.epsilon, self.alpha - y2))) * (self.alpha - y2) * (\n",
    "                torch.pow(self.theta / self.epsilon, self.alpha - y2 - 1)) * (1 / self.epsilon)\n",
    "            C = self.theta * A - self.omega * \\\n",
    "                torch.log(1 + torch.pow(self.theta / self.epsilon, self.alpha - y2))\n",
    "            if self.weight_map_mode:\n",
    "                loss2 = (A * delta_y2 - C) * weight_map[delta_y >= self.theta]\n",
    "            else:\n",
    "                loss2 = (A * delta_y2 - C)\n",
    "            return (loss1.sum() + loss2.sum()) / (len(loss1) + len(loss2))\n",
    "\n",
    "        elif self.loss_type == 'sl':\n",
    "            l = torch.abs(y_pred - y.float())\n",
    "            y_pred = torch.square(l)*torch.exp(y) / (1+torch.exp(self.a * (self.c - l)))\n",
    "            y_pred_sum = torch.sum(y_pred, dim=2)\n",
    "            # Sum over all elements and normalize\n",
    "            ret = torch.sum(y_pred_sum) / torch.numel(y_pred)\n",
    "            return ret\n",
    "\n",
    "\n",
    "def generate_weight_map(heatmap):\n",
    "    k_size = 3\n",
    "    weight_map = np.zeros_like(heatmap)\n",
    "    for i in range(heatmap.shape[0]):\n",
    "        for j in range(heatmap.shape[1]):\n",
    "            dilate = grey_dilation(heatmap[i,j], size=(k_size, k_size))\n",
    "            valid_ind = np.where(dilate > 0.2)\n",
    "            weight_map[i, j, valid_ind[0], valid_ind[1]] = 1\n",
    "    return weight_map\n",
    "\n",
    "\n",
    "def merge_weight_map(w_map):\n",
    "    w_map = w_map.astype(bool)\n",
    "    for i in range(w_map.shape[0]):\n",
    "        w_merged = np.bitwise_or.reduce(w_map[i, 1:w_map.shape[1]], axis=0)\n",
    "        w_map[i, 1:w_map.shape[1]] = w_merged\n",
    "    return w_map\n",
    "\n",
    "\n",
    "def plot_peak_maps(max_filter, peak_map, image):\n",
    "    plt.figure(1)\n",
    "    for i in range(3):\n",
    "        plt.subplot(3, 3, 3*i+1)\n",
    "        plt.imshow(image[i])\n",
    "        plt.subplot(3, 3, 3*i+2)\n",
    "        plt.imshow(max_filter[i])\n",
    "        plt.subplot(3, 3, 3*i+3)\n",
    "        plt.imshow(peak_map[i])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_maps(data, heatmap_gt, heatmap_pred, peak_map):\n",
    "    image = data.cpu().numpy().squeeze().transpose(1, 2, 0)\n",
    "    image = (image - image.min()) / (image.max() - image.min())\n",
    "    plt.figure(1)\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.imshow(image)\n",
    "    plt.title('Image')\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.imshow(peak_map)\n",
    "    plt.title('peak_map')\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.imshow(heatmap_gt)\n",
    "    plt.title('GT heatmap')\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.imshow(heatmap_pred)\n",
    "    plt.title('Predicted heatmap')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_heatmaps(image, heatmap_gt, heatmap_pred, peak_maps):\n",
    "    image = image.cpu().numpy().transpose(1, 2, 0)\n",
    "    image = (image - image.min()) / (image.max() - image.min())\n",
    "    plt.figure(1)\n",
    "    plt.imshow(image)\n",
    "    plt.title('Image')\n",
    "    if heatmap_gt.shape[0] == 7:\n",
    "        plt.figure(2, figsize=(30, 5)) # For 7 classes use this figsize, for 2 classes remove the figsize\n",
    "    else:\n",
    "        plt.figure(2)\n",
    "    num_plots = heatmap_gt.shape[0]\n",
    "    for i in range(num_plots):\n",
    "        plt.subplot(3, num_plots, i+1)\n",
    "        plt.imshow(heatmap_gt[i])\n",
    "        plt.title(f'GT - class [{i}]')\n",
    "        plt.subplot(3, num_plots, i+num_plots+1)\n",
    "        plt.imshow(heatmap_pred[i])\n",
    "        plt.title(f'Pred - class [{i}]')\n",
    "        plt.subplot(3, num_plots, i + 2*num_plots + 1)\n",
    "        plt.imshow(peak_maps[i])\n",
    "        plt.title(f'Peak maps - class [{i}]')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def get_model_name(arguments):\n",
    "    if arguments.weight_map:\n",
    "        model_name = f'c-{arguments.num_classes}_{arguments.loss_type}_b-{arguments.beta}_wm_e-{arguments.epochs}.pt' # Set W from effective number of samples\n",
    "    else:\n",
    "        model_name = f'c-{arguments.num_classes}_{arguments.loss_type}_b-{arguments.beta}_e-{arguments.epochs}.pt'\n",
    "    # model_name = f'c-{arguments.num_classes}_{arguments.loss_type}_cb-{arguments.class_balance}_wm-{arguments.weight_map}_b-{arguments.beta}_e-{arguments.epochs}.pt'\n",
    "    return model_name\n"
   ],
   "metadata": {
    "id": "4O43_hf4LkRr"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "4. Main"
   ],
   "metadata": {
    "id": "7-E6TE0xLyVt"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\"\"\"Parse arguments and train model on dataset.\"\"\"\n",
    "args = parse_args()\n",
    "model_name = get_model_name(args)\n",
    "path_save = os.path.join('saved models', model_name)\n",
    "print('Model will be saved at ' + path_save)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "cm_jet = mpl.cm.get_cmap('jet')\n",
    "\n",
    "dataset = MALARIA('', 'train', train=True, num_classes=args.num_classes)\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [1100, 108], generator=torch.Generator().manual_seed(42))  # [1100, 108]\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=0)\n",
    "\n",
    "model = localizerVgg.localizervgg16(num_classes=train_dataset.dataset.get_number_classes(), pretrained=True)\n",
    "model = model.to(device)\n",
    "\n",
    "# Count instances of each class\n",
    "ny = torch.DoubleTensor((list(train_dataset.dataset.instances_count().values()))).to(device)\n",
    "Eny = (1 - args.beta**ny)/(1 - args.beta)\n",
    "W = torch.unsqueeze(max(Eny) / Eny, dim=1)\n",
    "\n",
    "criterionGAM = Loss(args.loss_type, args.weight_map, Eny)\n",
    "\n",
    "optimizer_ft = optim.Adam(model.parameters(), lr=0.0001)\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer_ft, step_size=20, gamma=0.1)\n",
    "model.train()\n",
    "\n",
    "if args.num_classes == 2:\n",
    "  thr = [0.5, 0.8]\n",
    "elif args.num_classes == 7:\n",
    "  thr = [0.5, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]\n",
    "thr = np.array(thr).reshape(args.num_classes, 1, 1)\n",
    "\n",
    "for epoch in range(args.epochs):\n",
    "    # scheduler.step(epoch)\n",
    "    for batch_idx, (data, GAM, num_cells) in enumerate(train_loader):\n",
    "        data, GAM, num_cells = data.to(device, dtype=torch.float),  GAM.to(device), num_cells.to(device)\n",
    "\n",
    "        MAP = model(data)\n",
    "\n",
    "        # Create cMap for multi class\n",
    "        cMap = MAP.data.cpu().numpy()\n",
    "        cMap_min = cMap.min(axis=(2,3)).reshape((cMap.shape[0], cMap.shape[1], 1, 1))\n",
    "        cMap_max = cMap.max(axis=(2,3)).reshape((cMap.shape[0], cMap.shape[1], 1, 1))\n",
    "        cMap = (cMap - cMap_min) / (cMap_max - cMap_min)\n",
    "        cMap[cMap < thr] = 0\n",
    "        # Detect peaks in the predicted heat map:\n",
    "        peakMAPs = utils.detect_peaks_multi_channels_batch(cMap) # BUG\n",
    "\n",
    "        # Generate weight map\n",
    "        if args.weight_map:\n",
    "            # dilate GAM\n",
    "            weight_map = generate_weight_map(GAM.cpu().detach().numpy())\n",
    "            # Merge weight maps\n",
    "            # weight_map = merge_weight_map(weight_map)\n",
    "            weight_map = W * torch.Tensor(weight_map.reshape((weight_map.shape[0], weight_map.shape[1], -1))).to(device) + 1\n",
    "        else:\n",
    "            weight_map = 1\n",
    "\n",
    "        # if args.class_balance:\n",
    "        #     # Calculate (num_cells + 1) / Eny\n",
    "        #     class_balance_term = (num_cells + 1) / Eny\n",
    "        # else:\n",
    "        #     class_balance_term = 1\n",
    "\n",
    "\n",
    "        if batch_idx % 20 == 0:\n",
    "            plot_heatmaps(data[0], GAM[0].cpu().detach().numpy(), MAP[0].cpu().detach().numpy(), peakMAPs[0])\n",
    "\n",
    "        # MAP & GAM shape is [B, C, H, W]. Reshape to [B, C, H*W]\n",
    "        MAP = MAP.view(MAP.shape[0], MAP.shape[1], -1)\n",
    "        GAM = GAM.view(GAM.shape[0], GAM.shape[1], -1)\n",
    "\n",
    "        # Batch size 1\n",
    "        # pred_num_cells = np.sum(peakMAPs, axis=(1,2))\n",
    "        # Any batch size\n",
    "        pred_num_cells = np.sum(peakMAPs, axis=(2, 3))\n",
    "        pred_num_cells_batch = np.sum(pred_num_cells, axis=0)\n",
    "        num_cells_batch = num_cells.cpu().detach().numpy().sum(axis=0)\n",
    "        # Average absolute error of cells counting (average over batch)\n",
    "        fark = abs(pred_num_cells_batch - num_cells_batch) / num_cells.shape[0]\n",
    "\n",
    "        loss = criterionGAM(MAP, GAM, weight_map=weight_map)\n",
    "\n",
    "\n",
    "        optimizer_ft.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_ft.step()\n",
    "\n",
    "        if batch_idx % 1 == 0: # was 20\n",
    "            print(f'Epoch: [{epoch}][{batch_idx}/{len(train_loader)}]\\t loss: {loss: .3e}, AE:{fark}')\n",
    "            print(f'Average predicted counting of RBC: {pred_num_cells_batch[0]//num_cells.shape[0]}. GT: {num_cells_batch[0]//num_cells.shape[0]}')\n",
    "\n",
    "    torch.save(model.state_dict(), path_save)"
   ],
   "metadata": {
    "id": "G2VpfYyxL00F"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}